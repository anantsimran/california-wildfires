{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET_PATH = 'data/uci_ml_hackathon_fire_dataset_2012-05-09_2013-01-01_10k_train.hdf5'\n",
    "TEST_DATASET_PATH = 'data/uci_ml_hackathon_fire_dataset_2013-01-01_2014-01-01_5k_test.hdf5'\n",
    "\n",
    "def getDataDict(DatasetPath):\n",
    "    with h5py.File(DatasetPath, 'r') as f:\n",
    "        data = {}\n",
    "        for k in list(f):\n",
    "            data[k] = f[k][:]\n",
    "        return data\n",
    "\n",
    "train_data = getDataDict(TRAIN_DATASET_PATH)\n",
    "\n",
    "train_data.keys()\n",
    "\n",
    "def transformDateTime(datetime):\n",
    "    ret = np.asarray([x * np.ones((1,30, 30)) for x in datetime])\n",
    "    return ret\n",
    "\n",
    "\n",
    "def transformLandCover(landCover):\n",
    "    nanConvert = {\n",
    "        0: 0,\n",
    "        1: 0,\n",
    "        2: -1,\n",
    "        3: 0,\n",
    "        4: -1,\n",
    "        5: 0,\n",
    "        6: 0,\n",
    "        16:0\n",
    "    }\n",
    "    ret=[]\n",
    "    \n",
    "    for datapoint in landCover:\n",
    "        for i in range(17):\n",
    "            if i in nanConvert.keys():\n",
    "                datapoint[i][np.isnan(datapoint[i])]= nanConvert[i] \n",
    "        ret.append(datapoint)\n",
    "    return np.asarray(ret)\n",
    "\n",
    "\n",
    "def transformLatAndLong(val):\n",
    "    ret = np.asarray([x * np.ones((1,30, 30)) for x in val])\n",
    "    return ret\n",
    "\n",
    "#TODO : define temperature according to datetime average\n",
    "def transformMet(met):\n",
    "    nanConvert = {\n",
    "        0: 290,\n",
    "        1: 26,\n",
    "        2: 0,\n",
    "        3: 0,\n",
    "        4: 0,\n",
    "    }\n",
    "    met0=[]\n",
    "    met1=[]\n",
    "    for datapoint in met:\n",
    "        for i in range(5):\n",
    "            datapoint[0][i][np.isnan(datapoint[0][i])]= nanConvert[i] \n",
    "            datapoint[1][i][np.isnan(datapoint[1][i])]= nanConvert[i] \n",
    "        met0.append(datapoint[0])\n",
    "        met1.append(datapoint[1])\n",
    "    return np.asarray(met0),np.asarray(met1)\n",
    "\n",
    "def transformFire(fire):\n",
    "    return np.asarray(fire)\n",
    "\n",
    "#transform all of them into dict of 3d np arrays.\n",
    "#Augmentation step must take place after this.\n",
    "#Can store this in h5py file after this.\n",
    "def transformAndClean(data):\n",
    "    X = {}\n",
    "    Y= {}\n",
    "    X['datetime'] = transformDateTime(data['datetime'])\n",
    "    X['landCover'] = transformLandCover(data['land_cover'])\n",
    "    X['latitude'] = transformLatAndLong(data['latitude'])\n",
    "    X['longitude'] = transformLatAndLong(data['longitude'])\n",
    "    X['met0'], X['met1'] = transformMet(data['meteorology'])\n",
    "    X['observed'] = transformFire(data['observed'])\n",
    "    Y['target'] = transformFire(data['target'])\n",
    "    return X,Y\n",
    "\n",
    "X,Y = transformAndClean(train_data)\n",
    "train_data=None\n",
    "\n",
    "startDictionary={\n",
    "    'datetime':0,\n",
    "    'landCover':1,\n",
    "    'latitude':18,\n",
    "    'longitude':19,\n",
    "    'met0':20,\n",
    "    'met1':25,\n",
    "    'observed':30,\n",
    "    'target':0\n",
    "}\n",
    "\n",
    "lengthDictionary={\n",
    "    'datetime':1,\n",
    "    'landCover':17,\n",
    "    'latitude':1,\n",
    "    'longitude':1,\n",
    "    'met0':5,\n",
    "    'met1':5,\n",
    "    'observed':5,\n",
    "    'target':2\n",
    "}\n",
    "def flattenData(data):\n",
    "    length =0\n",
    "    for key,value in data.items():\n",
    "        length += value.shape[1]\n",
    "        n=value.shape[0]\n",
    "    ret = np.zeros((n,length,30,30))\n",
    "    for key,arr in data.items():     \n",
    "        for index,datapoint in enumerate(arr):\n",
    "            ret[index][startDictionary[key]: startDictionary[key]+lengthDictionary[key]][:][:]=datapoint        \n",
    "    return ret;\n",
    "\n",
    "flatX = flattenData(X)\n",
    "flatY = flattenData(Y)  \n",
    "\n",
    "X=None \n",
    "Y=None\n",
    "\n",
    "trainX,testX,trainY,testY = train_test_split(flatX,flatY,test_size=0.2,random_state = 42,shuffle=True)\n",
    "flatX=None\n",
    "flatY=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expects 4D input for X, Y\n",
    "def filterZeroData (X, Y, minFires=30):\n",
    "    count=0\n",
    "    for i in range(Y.shape[0]):\n",
    "        _, counts = np.unique(Y[i], return_counts=True)\n",
    "        if len(counts)<=1 or counts[1]<=minFires:\n",
    "            count+=1\n",
    "            \n",
    "    newX = np.zeros([X.shape[0] - count, X.shape[1], X.shape[2], X.shape[3]])\n",
    "    newY = np.zeros([Y.shape[0] - count, Y.shape[1], Y.shape[2], Y.shape[3]])\n",
    "    \n",
    "    j=0\n",
    "    for i in range(Y.shape[0]):\n",
    "        _, counts = np.unique(Y[i], return_counts=True)\n",
    "        if len(counts)==2:\n",
    "            if (counts[1]>minFires):\n",
    "                newX[j] = X[i]\n",
    "                newY[j] = Y[i]\n",
    "                j+=1\n",
    "    \n",
    "    return newX, newY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernelTransform(X, kernel_dim):\n",
    "    n_features = X.shape[1]\n",
    "    pad_width = (kernel_dim-1)//2\n",
    "    resultX = np.zeros([X.shape[0]*30*30, n_features*kernel_dim*kernel_dim])\n",
    "    for data in range(0, X.shape[0]):\n",
    "    #     print(feature_img.shape)\n",
    "    #     print(feature_img[features.index(9)].shape)\n",
    "        f_img_pad = np.pad(X[data], ((0,0), (pad_width, pad_width), (pad_width, pad_width)), 'edge')\n",
    "    #     print(f_img_pad[features.index(9)])\n",
    "    #     feature_line = np.zeros(n_features*kernel_dim*kernel_dim)\n",
    "    #     print(features.shape)\n",
    "        k=0\n",
    "        for i in range(30):\n",
    "            for j in range(30):\n",
    "                resultX[data*900+k] = f_img_pad[:,i:i+kernel_dim,j:j+kernel_dim].flatten()\n",
    "                k+=1\n",
    "    \n",
    "    return resultX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 35, 30, 30)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 2, 30, 30)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['datetime', 'Aspect', 'CBD', 'CBH', 'CC', 'CH', 'Elevation', \n",
    "           'No Data', 'Sparse', 'Tree', 'Shrub', 'Herb', 'Water', 'Barren', \n",
    "           'Developed', 'Snow-Ice', 'Agriculture', 'Slope', 'latitude', 'longitude',\n",
    "           'Temp0', 'RelHumid0','UWind0', 'VWind0', 'Precipitate0',\n",
    "           'Temp12', 'RelHumid12', 'UWind12', 'VWind12', 'Precipitate12',\n",
    "           'observed1','observed2', 'observed3','observed4', 'observed5']\n",
    "len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7200000, 35)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_train_X = trainX.transpose(0,2,3,1).reshape(trainX.shape[0]*trainX.shape[2]*trainX.shape[3],-1)\n",
    "flat_train_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "startDictionary={\n",
    "    'datetime':0,\n",
    "    'landCover':1,\n",
    "    'latitude':18,\n",
    "    'longitude':19,\n",
    "    'met0':20,\n",
    "    'met1':25,\n",
    "    'observed':30,\n",
    "    'target':0\n",
    "}\n",
    "\n",
    "lengthDictionary={\n",
    "    'datetime':1,\n",
    "    'landCover':17,\n",
    "    'latitude':1,\n",
    "    'longitude':1,\n",
    "    'met0':5,\n",
    "    'met1':5,\n",
    "    'observed':5,\n",
    "    'target':2\n",
    "}\n",
    "\n",
    "#### Layers\n",
    "* 0: Aspect \n",
    "* 1: Canopy Bulk Density\n",
    "* 2: Canopy Base Height\n",
    "* 3: Canopy Cover\n",
    "* 4: Canopy Height\n",
    "* 5: Elevelation\n",
    "* 6 to 15: Vegetation (Fractional Veg Class per layer)\n",
    "* 16: Slope\n",
    "\n",
    "#### Vegetation Layers\n",
    "* 6: No Data\n",
    "* 7: Sparse\n",
    "* 8: Tree\n",
    "* 9: Shrub\n",
    "* 10: Herb\n",
    "* 11: Water\n",
    "* 12: Barren\n",
    "* 13: Developed\n",
    "* 14: Snow-Ice\n",
    "* 15: Agriculture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = pd.DataFrame(flat_train_X, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>CBD</th>\n",
       "      <th>CBH</th>\n",
       "      <th>CC</th>\n",
       "      <th>CH</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>No Data</th>\n",
       "      <th>Sparse</th>\n",
       "      <th>Tree</th>\n",
       "      <th>...</th>\n",
       "      <th>Temp12</th>\n",
       "      <th>RelHumid12</th>\n",
       "      <th>UWind12</th>\n",
       "      <th>VWind12</th>\n",
       "      <th>Precipitate12</th>\n",
       "      <th>observed1</th>\n",
       "      <th>observed2</th>\n",
       "      <th>observed3</th>\n",
       "      <th>observed4</th>\n",
       "      <th>observed5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.200000e+06</td>\n",
       "      <td>7.200000e+06</td>\n",
       "      <td>7.200000e+06</td>\n",
       "      <td>7.200000e+06</td>\n",
       "      <td>7.200000e+06</td>\n",
       "      <td>7.200000e+06</td>\n",
       "      <td>7.200000e+06</td>\n",
       "      <td>7.200000e+06</td>\n",
       "      <td>7.200000e+06</td>\n",
       "      <td>7.200000e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>7.200000e+06</td>\n",
       "      <td>7.200000e+06</td>\n",
       "      <td>7.200000e+06</td>\n",
       "      <td>7.200000e+06</td>\n",
       "      <td>7.200000e+06</td>\n",
       "      <td>7.200000e+06</td>\n",
       "      <td>7.200000e+06</td>\n",
       "      <td>7.200000e+06</td>\n",
       "      <td>7.200000e+06</td>\n",
       "      <td>7.200000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.345524e+18</td>\n",
       "      <td>1.443239e+02</td>\n",
       "      <td>4.348882e+00</td>\n",
       "      <td>9.040829e+00</td>\n",
       "      <td>2.534833e+01</td>\n",
       "      <td>1.474523e+02</td>\n",
       "      <td>1.233443e+03</td>\n",
       "      <td>1.439570e-02</td>\n",
       "      <td>1.244688e-02</td>\n",
       "      <td>5.615111e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.965911e+02</td>\n",
       "      <td>3.596852e+01</td>\n",
       "      <td>1.407599e+00</td>\n",
       "      <td>4.988841e-01</td>\n",
       "      <td>8.150948e-06</td>\n",
       "      <td>7.289500e-02</td>\n",
       "      <td>4.347153e-02</td>\n",
       "      <td>4.760125e-02</td>\n",
       "      <td>3.125556e-02</td>\n",
       "      <td>3.433069e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.498228e+15</td>\n",
       "      <td>8.544380e+01</td>\n",
       "      <td>3.880711e+00</td>\n",
       "      <td>1.237087e+01</td>\n",
       "      <td>2.142645e+01</td>\n",
       "      <td>1.260076e+02</td>\n",
       "      <td>5.802670e+02</td>\n",
       "      <td>1.176224e-01</td>\n",
       "      <td>5.425514e-02</td>\n",
       "      <td>3.787194e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>8.397094e+00</td>\n",
       "      <td>2.128647e+01</td>\n",
       "      <td>2.425977e+00</td>\n",
       "      <td>2.162564e+00</td>\n",
       "      <td>5.457135e-05</td>\n",
       "      <td>2.599641e-01</td>\n",
       "      <td>2.039161e-01</td>\n",
       "      <td>2.129211e-01</td>\n",
       "      <td>1.740076e-01</td>\n",
       "      <td>1.820772e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.336594e+18</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-7.056320e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.678546e+02</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>-6.283561e+00</td>\n",
       "      <td>-1.039583e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.344768e+18</td>\n",
       "      <td>8.431040e+01</td>\n",
       "      <td>6.496000e-01</td>\n",
       "      <td>1.625600e+00</td>\n",
       "      <td>3.600000e+00</td>\n",
       "      <td>1.796000e+01</td>\n",
       "      <td>8.545632e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.600000e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.893503e+02</td>\n",
       "      <td>1.900000e+01</td>\n",
       "      <td>-2.941132e-01</td>\n",
       "      <td>-9.544525e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.345371e+18</td>\n",
       "      <td>1.496192e+02</td>\n",
       "      <td>3.792000e+00</td>\n",
       "      <td>6.496000e+00</td>\n",
       "      <td>2.288000e+01</td>\n",
       "      <td>1.313200e+02</td>\n",
       "      <td>1.327390e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.544000e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.992336e+02</td>\n",
       "      <td>2.900000e+01</td>\n",
       "      <td>1.609131e+00</td>\n",
       "      <td>5.146055e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.346100e+18</td>\n",
       "      <td>2.110928e+02</td>\n",
       "      <td>6.990400e+00</td>\n",
       "      <td>9.849600e+00</td>\n",
       "      <td>4.351200e+01</td>\n",
       "      <td>2.612400e+02</td>\n",
       "      <td>1.661222e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.328000e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.037559e+02</td>\n",
       "      <td>5.000000e+01</td>\n",
       "      <td>3.263401e+00</td>\n",
       "      <td>1.999557e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.356988e+18</td>\n",
       "      <td>3.580000e+02</td>\n",
       "      <td>3.657920e+01</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>9.100000e+01</td>\n",
       "      <td>4.612000e+02</td>\n",
       "      <td>3.851539e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.185415e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.043746e+01</td>\n",
       "      <td>1.037196e+01</td>\n",
       "      <td>1.350000e-03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           datetime        Aspect           CBD           CBH            CC  \\\n",
       "count  7.200000e+06  7.200000e+06  7.200000e+06  7.200000e+06  7.200000e+06   \n",
       "mean   1.345524e+18  1.443239e+02  4.348882e+00  9.040829e+00  2.534833e+01   \n",
       "std    2.498228e+15  8.544380e+01  3.880711e+00  1.237087e+01  2.142645e+01   \n",
       "min    1.336594e+18 -1.000000e+00  0.000000e+00 -1.000000e+00  0.000000e+00   \n",
       "25%    1.344768e+18  8.431040e+01  6.496000e-01  1.625600e+00  3.600000e+00   \n",
       "50%    1.345371e+18  1.496192e+02  3.792000e+00  6.496000e+00  2.288000e+01   \n",
       "75%    1.346100e+18  2.110928e+02  6.990400e+00  9.849600e+00  4.351200e+01   \n",
       "max    1.356988e+18  3.580000e+02  3.657920e+01  1.000000e+02  9.100000e+01   \n",
       "\n",
       "                 CH     Elevation       No Data        Sparse          Tree  \\\n",
       "count  7.200000e+06  7.200000e+06  7.200000e+06  7.200000e+06  7.200000e+06   \n",
       "mean   1.474523e+02  1.233443e+03  1.439570e-02  1.244688e-02  5.615111e-01   \n",
       "std    1.260076e+02  5.802670e+02  1.176224e-01  5.425514e-02  3.787194e-01   \n",
       "min   -1.000000e+00 -7.056320e+01  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    1.796000e+01  8.545632e+02  0.000000e+00  0.000000e+00  1.600000e-01   \n",
       "50%    1.313200e+02  1.327390e+03  0.000000e+00  0.000000e+00  6.544000e-01   \n",
       "75%    2.612400e+02  1.661222e+03  0.000000e+00  0.000000e+00  9.328000e-01   \n",
       "max    4.612000e+02  3.851539e+03  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "       ...        Temp12    RelHumid12       UWind12       VWind12  \\\n",
       "count  ...  7.200000e+06  7.200000e+06  7.200000e+06  7.200000e+06   \n",
       "mean   ...  2.965911e+02  3.596852e+01  1.407599e+00  4.988841e-01   \n",
       "std    ...  8.397094e+00  2.128647e+01  2.425977e+00  2.162564e+00   \n",
       "min    ...  2.678546e+02  4.000000e+00 -6.283561e+00 -1.039583e+01   \n",
       "25%    ...  2.893503e+02  1.900000e+01 -2.941132e-01 -9.544525e-01   \n",
       "50%    ...  2.992336e+02  2.900000e+01  1.609131e+00  5.146055e-01   \n",
       "75%    ...  3.037559e+02  5.000000e+01  3.263401e+00  1.999557e+00   \n",
       "max    ...  3.185415e+02  1.000000e+02  1.043746e+01  1.037196e+01   \n",
       "\n",
       "       Precipitate12     observed1     observed2     observed3     observed4  \\\n",
       "count   7.200000e+06  7.200000e+06  7.200000e+06  7.200000e+06  7.200000e+06   \n",
       "mean    8.150948e-06  7.289500e-02  4.347153e-02  4.760125e-02  3.125556e-02   \n",
       "std     5.457135e-05  2.599641e-01  2.039161e-01  2.129211e-01  1.740076e-01   \n",
       "min     0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%     0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%     0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%     0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "max     1.350000e-03  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "          observed5  \n",
       "count  7.200000e+06  \n",
       "mean   3.433069e-02  \n",
       "std    1.820772e-01  \n",
       "min    0.000000e+00  \n",
       "25%    0.000000e+00  \n",
       "50%    0.000000e+00  \n",
       "75%    0.000000e+00  \n",
       "max    1.000000e+00  \n",
       "\n",
       "[8 rows x 35 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N Features:  18\n",
      "(8000, 18, 30, 30)\n"
     ]
    }
   ],
   "source": [
    "# features = [2,4,5,9,10,11,30,31,32,33,34]\n",
    "features = [1,2,4,5,6,9,10,11,17,20,21,22,23,30,31,32,33,34]\n",
    "print(\"N Features: \",len(features))\n",
    "\n",
    "modelTrainX =  np.array([x[features] for x in trainX])\n",
    "modelTrainY =  np.array([y[[0]] for y in trainY])\n",
    "modelTestX =  np.array([x[features] for x in testX])\n",
    "modelTestY =  np.array([y[[0]] for y in testY])\n",
    "print(modelTrainX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3944, 18, 30, 30)\n",
      "(3944, 1, 30, 30)\n"
     ]
    }
   ],
   "source": [
    "filterTrainX, filterTrainY = filterZeroData(modelTrainX, modelTrainY, minFires=30)\n",
    "print(filterTrainX.shape)\n",
    "print(filterTrainY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabularizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3549600, 162) (3549600,)\n"
     ]
    }
   ],
   "source": [
    "kernel_dim=5\n",
    "# mtrX = filterTrainX.transpose(0,2,3,1).reshape(filterTrainX.shape[0]*filterTrainX.shape[2]*filterTrainX.shape[3],-1)\n",
    "mtrX = kernelTransform(filterTrainX, 3)\n",
    "mtrY = filterTrainY.transpose(0,2,3,1).flatten()\n",
    "print(mtrX.shape, mtrY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800000, 162) (1800000,)\n"
     ]
    }
   ],
   "source": [
    "mteX = kernelTransform(modelTestX, 3)\n",
    "mteY = modelTestY.transpose(0,2,3,1).flatten()\n",
    "print(mteX.shape, mteY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nTrainSamples=10000\n",
    "nTestSamples=1000\n",
    "start = int(np.random.rand()*(mtrX.shape[0]-nTrainSamples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of unique values of the said array:\n",
      "[[0.000e+00 1.000e+00]\n",
      " [9.076e+03 9.240e+02]]\n"
     ]
    }
   ],
   "source": [
    "smallX = mtrX[start:start+nTrainSamples]\n",
    "smallY = mtrY[start:start+nTrainSamples]\n",
    "smallTestX = mteX[:nTestSamples]\n",
    "smallTestY = mteY[:nTestSamples]\n",
    "# np.unique(smallY)\n",
    "unique_elements, counts_elements = np.unique(smallY, return_counts=True)\n",
    "print(\"Frequency of unique values of the said array:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM begins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 924, 1: 9076}\n"
     ]
    }
   ],
   "source": [
    "kernels = ('linear', 'poly', 'rbf')\n",
    "weights = {0:counts_elements[1], 1:counts_elements[0]}\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC( gamma='scale', kernel=kernels[2], class_weight=weights)\n",
    "clf.fit(smallX, smallY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_p = clf.predict(smallX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(smallTestX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.766\n",
      "Precision: 0.1956521739130435\n",
      "Recall: 0.8181818181818182\n",
      "F1 Score: 0.8230230461557998\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(smallY, y_tr_p))\n",
    "print(\"Precision:\",metrics.precision_score(smallY, y_tr_p))\n",
    "print(\"Recall:\",metrics.recall_score(smallY, y_tr_p))\n",
    "print(\"F1 Score:\",metrics.f1_score(smallY, y_tr_p, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.975\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 Score: 0.9626582278481012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\risha\\Anaconda3\\envs\\UCI - CS274P\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(smallTestY, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(smallTestY, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(smallTestY, y_pred))\n",
    "print(\"F1 Score:\",metrics.f1_score(smallTestY, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Even after improving subsampling and training with 10,000 data points we observe a bad performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appendix: POC for how to transpose the Data Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 1.,  2.],\n",
       "         [ 3.,  4.]],\n",
       "\n",
       "        [[ 5.,  6.],\n",
       "         [ 7.,  8.]]],\n",
       "\n",
       "\n",
       "       [[[ 9., 10.],\n",
       "         [11., 12.]],\n",
       "\n",
       "        [[13., 14.],\n",
       "         [15., 16.]]]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros([2,2,2,2])\n",
    "a[0][0][0][0] = 1\n",
    "a[0][0][0][1] = 2\n",
    "a[0][0][1][0] = 3\n",
    "a[0][0][1][1] = 4\n",
    "a[0][1][0][0] = 5\n",
    "a[0][1][0][1] = 6\n",
    "a[0][1][1][0] = 7\n",
    "a[0][1][1][1] = 8\n",
    "a[1][0][0][0] = 9\n",
    "a[1][0][0][1] = 10\n",
    "a[1][0][1][0] = 11\n",
    "a[1][0][1][1] = 12\n",
    "a[1][1][0][0] = 13\n",
    "a[1][1][0][1] = 14\n",
    "a[1][1][1][0] = 15\n",
    "a[1][1][1][1] = 16\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 4)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a.transpose(0,2,3,1)\n",
    "b = c.reshape(c.shape[0]*c.shape[1]*c.shape[2],-1)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  5.,  0.,  0.],\n",
       "       [ 2.,  6.,  0.,  0.],\n",
       "       [ 3.,  7.,  0.,  0.],\n",
       "       [ 4.,  8.,  0.,  0.],\n",
       "       [ 9., 13.,  0.,  0.],\n",
       "       [10., 14.,  0.,  0.],\n",
       "       [11., 15.,  0.,  0.],\n",
       "       [12., 16.,  0.,  0.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(8000):\n",
    "    if modelTrainX[i][2][0][0] == 1:\n",
    "        print (i)\n",
    "        print(modelTrainX[i][0][0][0])\n",
    "        print(modelTrainX[i][1][0][0])\n",
    "        print(modelTrainX[i][2][0][0])\n",
    "        print(modelTrainX[i][3][0][0])\n",
    "        print(modelTrainX[i][4][0][0])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 1., 0.])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtrX[24*30*30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They match!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POC on how to filter zero vlaues prediction images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for i in range(len(filterTrainY)):\n",
    "    if len(np.unique(filterTrainY[i]))<=1:\n",
    "#         print(i)\n",
    "        count+=1\n",
    "\n",
    "print (count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(filterTrainY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POC on generating new features (like kernels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6852, 13, 30, 30)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filterTrainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6166800, 13)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtrX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 32, 32)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6852, 13, 30, 30)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filterTrainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 1., 2., 2.],\n",
       "        [1., 1., 2., 2.],\n",
       "        [3., 3., 4., 4.],\n",
       "        [3., 3., 4., 4.]],\n",
       "\n",
       "       [[5., 5., 6., 6.],\n",
       "        [5., 5., 6., 6.],\n",
       "        [7., 7., 8., 8.],\n",
       "        [7., 7., 8., 8.]]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_width=1\n",
    "pad = np.pad(a[0], ((0,0), (pad_width, pad_width), (pad_width, pad_width)), 'edge')\n",
    "pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 3, 3)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_img_pad[:,i:i+kernel_dim,j:j+kernel_dim].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117,)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_img_pad[:,i:i+kernel_dim,j:j+kernel_dim].flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rx = np.ones([1, 117, 30, 30])\n",
    "rx = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
